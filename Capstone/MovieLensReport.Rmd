---
title: "MovieLens"
author: "Simone Trindade Steel"
date: "25/07/2020"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Introduction Executive Summary

This report shows the RMSE results of movie ratings predictions using the "edx" data set for training and the "validation" set for evaluation.

After exploring and visualising the relationships between predictors, these are the key insights used in the construction of the prediction model:

1. Ratings for films in recent decades have declined;

2. There is no indication that genre influences rating and

3. Categorisation models are not appropriate for the prediction, therefore an adjusted Naive Bayes approach was taken in order to account for movie, user and decade biases in the predictors.


The code provided by EDX to load the appropriate data and libraries has been used in the generation of this report.

For ease of reference, the section of the Report.R file is commented as "# Create edx set, validation set (final hold-out test set)".



```{r creation-of-data-sets, include=FALSE}
##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(stringr)
library(tidyverse)
library(dplyr)
library(caret)
library(rpart)
library(ggplot2)
library(tinytex)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 4.0 or later
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

```



## 2. Method and analysis

The initial step for analysis was to glance at the edx (training) dataset. Its structure and sample data can be seen here:

```{r edx-data}
str(edx)
head(edx)
```

## 2.1. Analysing rating and time relationship

The section of the Report.R file that refers to the data analysis is also commented as "# Analysing rating and time relationship".


As seen in the graph below, ratings and time are weakly, but negatively correlated. Recent films have slightly lower ratings than older ones.

```{r edx-libraries, echo=FALSE}
# Glancing at decades, it appears that average ratings have been declining
tidy_edx <- edx %>% mutate(year = str_trunc(title, 5, side="left", ellipsis=""))
tidy_edx <- tidy_edx %>% mutate(year = str_trunc(year, 4, side="right", ellipsis=""))
tidy_edx <- tidy_edx %>% mutate(year = as.numeric(year))
tidy_edx <- tidy_edx %>% mutate(decade = round(year - 1900)/10)
tidy_edx %>%
  group_by(decade) %>%
  summarise(m=mean(rating)) %>%
  ggplot(aes(x=decade, y=m)) +
  geom_point()
```




## 2.2. Analysing rating and genre relationship

The section of the Report.R file that refers to the data analysis is also commented as "# Analysing rating and genre relationship".

Looking into the most common genres, that is the ones with over one million reviews, ratings do not seem to vary across them.


```{r edx-analysis-genre, echo=FALSE}
tidy_edx_genre <- edx %>% mutate(comedy=ifelse(str_detect(genres, "Comedy"), 1, 0),
                                 action=ifelse(str_detect(genres, "Action"), 1, 0),
                                 romance=ifelse(str_detect(genres, "Romance"), 1, 0),
                                 thriller=ifelse(str_detect(genres, "Thriller"), 1, 0),
                                 adventure=ifelse(str_detect(genres, "Adventure"), 1, 0),
                                 scifi=ifelse(str_detect(genres, "Sci-Fi"), 1, 0),
                                 drama=ifelse(str_detect(genres, "Drama"), 1, 0),
                                 children=ifelse(str_detect(genres, "Children"), 1, 0),
                                 fantasy=ifelse(str_detect(genres, "Fantasy"), 1, 0),
                                 mystery=ifelse(str_detect(genres, "Mystery"), 1, 0),
                                 horror=ifelse(str_detect(genres, "Horror"), 1, 0),
                                 western=ifelse(str_detect(genres, "Western"), 1, 0),
                                 war=ifelse(str_detect(genres, "War"), 1, 0),
                                 musical=ifelse(str_detect(genres, "Musical"), 1, 0),
                                 crime=ifelse(str_detect(genres, "Crime"), 1, 0),
                                 documentary=ifelse(str_detect(genres, "Documentary"), 1, 0),
                                 animation=ifelse(str_detect(genres, "Animation"), 1, 0)) %>%
  gather("genre_name", "genre_value", comedy:animation) 

tidy_edx_genre %>%
  group_by(genre_name) %>%
  summarise(s=sum(genre_value)) %>%
  arrange(desc(s))

rm(tidy_edx_genre) # free up memory

```


## 2.3. Exploring genre and time together


Similar conclusion is drawn when genre by decade analysis is performed. That is, no significant difference in trend, as demonstrated in the graph below. Genre will be discarded as a predictor.

See "# Exploring genre and time together" in the Report.R script.

```{r edx-analysis-genre-time, echo=FALSE}
# Genres that have over 1million entries: Action, Adventure, Comedy, Crime, Drama, Romance, Sci-Fi
# Is there a trend by genre over time?
tidy_edx <- tidy_edx %>% mutate(action=ifelse(str_detect(genres, "Action"), 1, 0),
                                adventure=ifelse(str_detect(genres, "Adventure"), 1, 0),
                                comedy=ifelse(str_detect(genres, "Comedy"), 1, 0),
                                crime=ifelse(str_detect(genres, "Crime"), 1, 0),
                                drama=ifelse(str_detect(genres, "Drama"), 1, 0),
                                romance=ifelse(str_detect(genres, "Romance"), 1, 0),
                                scifi=ifelse(str_detect(genres, "Sci-Fi"), 1, 0),
                                thriller=ifelse(str_detect(genres, "Thriller"), 1, 0)) %>%
  gather("genre_name", "genre_value", action:scifi)

tidy_edx %>%
  group_by(genre_name, decade) %>%
  summarise(m=mean(rating)) %>%
  ungroup() %>%
  ggplot(aes(x=decade, y=m)) +
  geom_point() +
  facet_grid(genre_name ~ ., scales = "free") 

# Conclusion: there is no significant difference by genre, 
# therefore, classification models will be discarded (nearest neighbours, decision trees, clustering)
rm(tidy_edx) # free up memory

# Add decade to training and test data sets

edx <- edx %>% mutate(year = str_trunc(title, 5, side="left", ellipsis="")) 
edx <- edx %>% mutate(year = str_trunc(year, 4, side="right", ellipsis=""))
edx <- edx %>% mutate(year = as.numeric(year))
edx <- edx %>% mutate(decade = round(year - 1900)/10)

validation <- validation %>% mutate(year = str_trunc(title, 5, side="left", ellipsis="")) 
validation <- validation %>% mutate(year = str_trunc(year, 4, side="right", ellipsis=""))
validation <- validation %>% mutate(year = as.numeric(year))
validation <- validation %>% mutate(decade = round(year - 1900)/10)
validation <- validation %>% mutate(decade = round(year - 1900)/10)

```



## 2.4. Chosing an appropriate predictive model

This report will attempt to improve on Naive Bayes, using movie, user and time as biases. Regularisation to control for differences in number of ratings per movie will also be applied.

The section of the Report.R script is commented as "# Chosing an appropriate predictive model".


```{r edx-analysis-model, include=FALSE}

# Strategy is to improving on Naive Bayes to minimise error: 
# mean + movie bias + user bias + decade bias
# (and adopting the best regularisation parameter: 5)

lambdas <- seq(0, 10, 0.25)
rmses <- sapply(lambdas, function(l){
  
  m_movie <- mean(edx$rating)
  
  b_m <- edx %>%
    group_by(movieId) %>%
    summarize(b_m = sum(rating - m_movie)/(n()+l))
  
  b_u <- edx %>% 
    left_join(b_m, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_m - m_movie)/(n()+l))
  
  b_t <- edx %>% 
    left_join(b_m, by="movieId") %>%
    group_by(decade) %>%
    summarize(b_t = sum(rating - b_m - m_movie)/(n()+l))
  
  predicted_ratings <- 
    validation %>% 
    left_join(b_m, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_t, by = "decade") %>%
    mutate(pred = m_movie + b_m + b_u + b_t) %>%
    .$pred
  return(RMSE(predicted_ratings, validation$rating))
})


```

## 3. Results 

The results section of the Report.R script is commented as "Results".

The lambda parameter that minimises RMSE is
```{r edx-analysis-lambda, echo=FALSE}
lambda <- lambdas[which.min(rmses)]
print(c("Lamba = ", lambda)) # Best regularisation parameter
```

This can be visualised here:

```{r edx-analysis-lambdagraph, echo=FALSE}
qplot(lambdas, rmses)  
```

## 4. Conclusion

The conclusion of this report is that the improved Naive Bayes model that takes into account movie, user and decade produces an RMSE below 0.8649, as seen in the table below.

```{r edx-analysis-rmses, echo=FALSE}
rmse_results <- data.frame(method="Regularized Movie, User and Time Effect Model", RMSE = min(rmses))
rmse_results %>% knitr::kable()
```

This report has limitations, insofar as it has not explored the use of multiple predictive models or ensemble of models, which could yield better overall results. Future work could also include rounding of half-ratings, given that integers are predominant across the full data set.
